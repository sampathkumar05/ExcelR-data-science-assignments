# -*- coding: utf-8 -*-
"""
Created on Sat Dec 16 09:17:33 2023

@author: SAMPATH
"""

#===FORECASTING (TIMESERIES)===========================================================#
#completed
#FINAL CODE
#===Airlinesdata=======================================================

#IMPORTING THE DATA
import pandas as pd
import numpy as np
Ald = pd.read_excel('Airlines+Data.xlsx')

len(Ald)
list(Ald)


##EDA
# line plot
Ald.plot()

# create a histogram plot
from matplotlib import pyplot
Ald.hist()
pyplot.show()

# Lag plot
# create a scatter plot
from matplotlib import pyplot
from pandas.plotting import lag_plot
lag_plot(Ald)
pyplot.show()

# create an autocorrelation plot
from matplotlib import pyplot
pyplot.figure(figsize = (60,10))
from statsmodels.graphics.tsaplots import plot_acf
Ald = pd.read_excel('Airlines+Data.xlsx', header=0, index_col=0,parse_dates=True)
plot_acf(Ald,lags=90)
pyplot.show()

# splitting the data
# Assuming 'Month' is the timestamp and 'Passengers' is the target variable
Ald['Month'] = pd.to_datetime(Ald['Passengers'])
Ald.set_index('Month', inplace=True)
Ald

# Train-test split
from sklearn.model_selection import train_test_split
train_size = int(len(Ald) * 0.8)
train, test = Ald[:train_size], Ald[train_size:]

# SARIMA Model
from statsmodels.tsa.statespace.sarimax import SARIMAX
model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
result = model.fit(disp=False)

# Forecast
predictions = result.get_forecast(steps=len(test))
predicted_values = predictions.predicted_mean

# Evaluate model
from sklearn.metrics import mean_squared_error
from math import sqrt
rmse = sqrt(mean_squared_error(test['Passengers'], predicted_values))
print("RMSE for Airlines data Passengers Forecasting:", rmse)

# Smoothing models : KERNAL SMOOTHING
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Generate random data
np.random.seed(42)
Ald = np.random.normal(size=100)

# Kernel smoothing using a Gaussian kernel
def kernel_smooth(Ald, kernel_width):
    smoothed_data = np.zeros_like(Ald)
    for i, x in enumerate(Ald):
        weights = norm.pdf((x - Ald) / kernel_width)
        smoothed_data[i] = np.sum(weights * Ald) / np.sum(weights)
    return smoothed_data

# Set the kernel width (bandwidth)
kernel_width = 0.5

# Apply kernel smoothing
smoothed_data = kernel_smooth(Ald, kernel_width)

# Plot the original and smoothed data
plt.figure(figsize=(10, 6))
plt.plot(Ald, label='Original Data', linestyle='None', marker='o', alpha=0.5)
plt.plot(smoothed_data, label=f'Smoothed Data (Kernel Width={kernel_width})', color='red')
plt.legend()
plt.title('Kernel Smoothing Example')
plt.show()

# Smoothing models : EXPONENTIAL SMOOTHING
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Generate example time series data
np.random.seed(42)
Ald = np.random.randn(100)  # Replace this with your own time series data

# Convert data to a pandas Series
time_series = pd.Series(Ald)

# Function for exponential smoothing
def exponential_smoothing(series, alpha):
    result = [series[0]]  # Initialize with the first value in the series

    for i in range(1, len(series)):
        result.append(alpha * series[i] + (1 - alpha) * result[i - 1])

    return result

# Set the smoothing parameter (alpha)
alpha = 0.2

# Apply exponential smoothing
smoothed_data = exponential_smoothing(time_series, alpha)

# Plot the original and smoothed data
plt.figure(figsize=(10, 6))
plt.plot(time_series, label='Original Data', linestyle='None', marker='o', alpha=0.5)
plt.plot(smoothed_data, label=f'Smoothed Data (Alpha={alpha})', color='red')
plt.legend()
plt.title('Exponential Smoothing Example')
plt.show()

#===CocaCola_Sales_Rawdata=======================================================


#IMPORTING THE DATA
import pandas as pd
import numpy as np

# Load CocaCola prices data (replace 'your_data.csv' with your actual file)
cc = pd.read_excel('CocaCola_Sales_Rawdata.xlsx')
list(cc)

# line plot
cc.plot()

# create a histogram plot
from matplotlib import pyplot
cc.hist()
pyplot.show()

# create a density plot
from matplotlib import pyplot
cc.plot(kind='kde')
pyplot.show()


# create a boxplot of yearly data
# days vs each year
from pandas import DataFrame
from pandas import Grouper
from matplotlib import pyplot
cc = pd.read_excel('CocaCola_Sales_Rawdata.xlsx', header=0, index_col=0,parse_dates=True,squeeze=True)
groups = cc.groupby(Grouper(freq='A'))
years = DataFrame()
for name, group in groups:
    years[name.year] = group.values
    
years

years.boxplot()
pyplot.show()


# Lag plot
# create a scatter plot
from matplotlib import pyplot
from pandas.plotting import lag_plot
lag_plot(cc)
pyplot.show()

# create an autocorrelation plot
from matplotlib import pyplot
pyplot.figure(figsize = (40,10))
from statsmodels.graphics.tsaplots import plot_acf
cc = pd.read_excel('CocaCola_Sales_Rawdata.xlsx', header=0, index_col=0,parse_dates=True)
plot_acf(cc,lags=90)
pyplot.show()


#converting the quarter data to datetime
cc = pd.read_excel('CocaCola_Sales_Rawdata.xlsx')
cc['Quarter'] = pd.to_datetime(cc['Quarter'].str.replace('Q', ''), format='%m_%y') + pd.offsets.QuarterBegin()
cc

# Assuming 'Quarter' is the timestamp and 'Sales' is the target variable
cc['Quarter'] = pd.to_datetime(cc['Sales'])
cc.set_index('Quarter', inplace=True)
cc

# Train-test split
from sklearn.model_selection import train_test_split
train_size = int(len(cc) * 0.8)
train, test = cc[:train_size], cc[train_size:]

# SARIMA Model
from statsmodels.tsa.statespace.sarimax import SARIMAX
model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
result = model.fit(disp=False)

# Forecast
predictions = result.get_forecast(steps=len(test))
predicted_values = predictions.predicted_mean

# Evaluate model
from sklearn.metrics import mean_squared_error
from math import sqrt
rmse = sqrt(mean_squared_error(test['Sales'], predicted_values))
print("RMSE for CocaCola_Sales_Rawdata Passengers Forecasting:", rmse)

# Smoothing models : KERNAL SMOOTHING
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Generate random data
np.random.seed(42)
cc = np.random.normal(size=100)

# Kernel smoothing using a Gaussian kernel
def kernel_smooth(cc, kernel_width):
    smoothed_data = np.zeros_like(cc)
    for i, x in enumerate(cc):
        weights = norm.pdf((x - cc) / kernel_width)
        smoothed_data[i] = np.sum(weights * cc) / np.sum(weights)
    return smoothed_data

# Set the kernel width (bandwidth)
kernel_width = 0.5

# Apply kernel smoothing
smoothed_data = kernel_smooth(cc, kernel_width)

# Plot the original and smoothed data
plt.figure(figsize=(10, 6))
plt.plot(cc, label='Original Data', linestyle='None', marker='o', alpha=0.5)
plt.plot(smoothed_data, label=f'Smoothed Data (Kernel Width={kernel_width})', color='red')
plt.legend()
plt.title('Kernel Smoothing Example')
plt.show()

# Smoothing models : EXPONENTIAL SMOOTHING
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Generate example time series data
np.random.seed(42)
cc = np.random.randn(100)  # Replace this with your own time series data

# Convert data to a pandas Series
time_series = pd.Series(cc)

# Function for exponential smoothing
def exponential_smoothing(series, alpha):
    result = [series[0]]  # Initialize with the first value in the series

    for i in range(1, len(series)):
        result.append(alpha * series[i] + (1 - alpha) * result[i - 1])

    return result

# Set the smoothing parameter (alpha)
alpha = 0.2

# Apply exponential smoothing
smoothed_data = exponential_smoothing(time_series, alpha)

# Plot the original and smoothed data
plt.figure(figsize=(10, 6))
plt.plot(time_series, label='Original Data', linestyle='None', marker='o', alpha=0.5)
plt.plot(smoothed_data, label=f'Smoothed Data (Alpha={alpha})', color='red')
plt.legend()
plt.title('Exponential Smoothing Example')
plt.show()

'''
CONCLUSION:
I WILL APPLY THE FORECASTING THE METHODS TO THE AIR LINES DATA BECAUSE IT HAS LESS RMSE THAN THE COCACOLA DATA
'''