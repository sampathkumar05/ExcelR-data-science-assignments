# -*- coding: utf-8 -*-
"""
Created on Mon Nov 27 18:27:03 2023

@author: SAMPATH
"""

#LOGISTIC REGRESSION
#COMPLETED

#===IMPORTING THE DATA===============================================
import pandas as pd
import numpy as np
Ass_6=pd.read_csv("bank-full.csv")
list(Ass_6)
Ass_6.dtypes
Ass_6.shape
Ass_6.head()
Ass_6

#===EDA - Exploratory Data Analysis==================================

#To find mathematical relations
math=Ass_6.describe()
print(math)

#Correlation
corr=Ass_6.corr()
print(corr)

#Heatmap of the correlation matrix
import matplotlib.pyplot as plt
import seaborn as sns
sns.heatmap(Ass_6.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

#Histogram for a numerical variable
plt.hist(Ass_6['age'], bins=20, color='blue', alpha=0.7)
plt.title('Histogram of Numerical Column')
plt.xlabel('age')
plt.ylabel('Frequency')
plt.show()

#Countplot for a categorical variable
sns.countplot(x='y', data=Ass_6)
plt.title('Countplot of Categorical Column')
plt.show()

#Scatter plot for two numerical variables
plt.scatter(Ass_6['pdays'], Ass_6['previous'])
plt.title('Scatter Plot')
plt.xlabel('pdays')
plt.ylabel('previous')
plt.show()

#Boxplot for a numerical and a categorical variable
sns.boxplot(x='y', y='age', data=Ass_6)
plt.title('Boxplot of Numerical Column by Category')
plt.show()


#===DATA TRANSFORMTION================================================
#label encoding
from sklearn.preprocessing import LabelEncoder
LE=LabelEncoder()
Ass_6['job']=LE.fit_transform(Ass_6['job'])
Ass_6['marital']=LE.fit_transform(Ass_6['marital'])
Ass_6['education']=LE.fit_transform(Ass_6['education'])
Ass_6['default']=LE.fit_transform(Ass_6['default'])
Ass_6['housing']=LE.fit_transform(Ass_6['housing'])
Ass_6['contact']=LE.fit_transform(Ass_6['contact'])
Ass_6['day']=LE.fit_transform(Ass_6['day'])
Ass_6['month']=LE.fit_transform(Ass_6['month'])
Ass_6['poutcome']=LE.fit_transform(Ass_6['poutcome'])


#splitting as x nd y
Y=Ass_6["y"]
X=Ass_6.iloc[:,[0,5,11,12,13,14]] 

#standardization
from sklearn.preprocessing import StandardScaler
SS = StandardScaler()
SS_X = SS.fit_transform(X)
SS_X = pd.DataFrame(SS_X)
SS_X

Ass_6

#===MODEL FITTING======================================================
#logistic regression
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(SS_X,Y)
Y_pred = logreg.predict(SS_X)

#metrics
from sklearn.metrics import accuracy_score
ac = accuracy_score(Y,Y_pred)
print("Accuracy score:", ac.round(2))

from sklearn.metrics import recall_score
rs = recall_score(Y,Y_pred)
print("Sensitivity score:", rs.round(2))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y,Y_pred)
cm

TN = cm[0,0]
FP = cm[0,1]

TNR = TN/(TN + FP)
print("Specificity score:", TNR.round(2))

from sklearn.metrics import f1_score
fs=f1_score(Y,Y_pred)
print("f1 score:",fs.round(2))


#===ROC CURVE & AREA UNDER THE CURVE==================================

Ass_6["Y_predected_prob"] = logreg.predict_proba(SS_X)[:,1]
Ass_6.head()

from sklearn.metrics import roc_curve,roc_auc_score

#Calculate the AUC (Area Under the Curve)
auc = roc_auc_score(Y,Ass_6["Y_predected_prob"])
fpr,tpr,dummy = roc_curve(Y,Ass_6["Y_predected_prob"],pos_label=1)

#Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()


#Area under the curve
import matplotlib.pyplot as plt
plt.scatter(fpr,tpr)
plt.plot(fpr,tpr,color='red')
plt.xlabel("True positive Rate")
plt.ylabel("False positive Rate")
plt.title('Area Under the Curve (AUC)')
plt.show()

print("Area under curve:",roc_auc_score(Y,Ass_6["Y_predected_prob"]).round(3))
#-----------------------------------------------------------------

# Data partition
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(SS_X,Y,test_size=0.30)

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()

logreg.fit(X_train,Y_train)
Y_pred_train = logreg.predict(X_train)
Y_pred_test  = logreg.predict(X_test)

# metrics
from sklearn.metrics import accuracy_score
ac_train = accuracy_score(Y_train,Y_pred_train)
ac_test = accuracy_score(Y_test,Y_pred_test)

# cross validation for logistic regression results
training_accuracy = []
test_accuracy = []

for i in range(1,100):
    X_train,X_test,Y_train,Y_test = train_test_split(SS_X,Y,test_size=0.30,random_state=i)
    logreg.fit(X_train,Y_train)
    Y_pred_train = logreg.predict(X_train)
    Y_pred_test  = logreg.predict(X_test)
    training_accuracy.append(accuracy_score(Y_train,Y_pred_train))
    test_accuracy.append(accuracy_score(Y_test,Y_pred_test))
 
print("\n")
print("Training Accuracy:", ac_train.round(2))
print("Test Accuracy:", ac_test.round(2))
print("\t***cross validation for logistic regression results***")
print("Cross validation training results:",pd.DataFrame(training_accuracy).mean().round(2))
print("Cross validation test results:",pd.DataFrame(test_accuracy).mean().round(2))





